# ðŸ“š AI-Powered Multi-Agent Research Assistant  

An AI-powered multi-agent system designed to automate research workflows by collaborating AI agents for searching, summarizing, fact-checking, and generating research content.

---

## ðŸ“Œ Problem Statement  

**Challenge:**  
Modern research processes require manually sourcing, analyzing, and summarizing large volumes of data, which is time-consuming and error-prone.

**Why AI Agents?**  
AI agents can independently handle specialized tasks and work collaboratively, improving speed, accuracy, and reducing cognitive load for human researchers.

**Unique Value of Multi-Agent Collaboration:**  
- **Task Specialization:** Different agents handle different jobs efficiently.  
- **Parallel Processing:** Multiple agents run concurrently.  
- **Cross-Verification:** Fact-checking improves accuracy.

---

## ðŸ“Œ Project Description  

The project is a Multi-Agent Research Assistant where autonomous AI agents interact to handle user research queries by:

- Retrieving relevant information  
- Summarizing findings  
- Fact-checking content  
- Generating a polished response  

**How It Works:**  
1. **User Query Input**  
2. **Search Agent:** Fetches relevant online data  
3. **Summarizer Agent:** Condenses retrieved data  
4. **Fact-Checker Agent:** Validates important claims  
5. **Content Generator Agent:** Crafts a final structured response  

Agents communicate through a central controller or agent orchestrator.

---

## ðŸ“Œ Tools, Libraries, and Frameworks  

- **OpenAI API (openai 1.x SDK)**  
- **LangChain**  
- **Streamlit** (for UI)
- **Python 3.11**  
- *(Optional experimental modules)*: MoviePy, gTTS  

---

## ðŸ“Œ LLM Selection  

**Primary Model:**  
- `GPT-4o` via OpenAI API  
  _Best for summarization, reasoning, and high-quality generation._

**Free-Tier/Backup Models:**  
- Google Gemini 1.5 Pro (makersuite / google.generativeai SDK)  
- Mistral 7B / Zephyr from Hugging Face  

**Why These Models?**  
GPT-4o for accuracy and reasoning, Gemini for a free-tier alternative, and Mistral for offline, open-source local inference.

---

## ðŸ“Œ Repository Structure  

```bash
multi-agent-research-assistant/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ data_gatherer.py
â”‚   â”œâ”€â”€ summarizer_agent.py
â”‚   â”œâ”€â”€ fact_checker_agent.py
â”‚   â””â”€â”€ report_maker.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ orchestrator.py
â”œâ”€â”€ .env
â””â”€â”€ README.md
